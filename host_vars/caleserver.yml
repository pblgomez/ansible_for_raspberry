---
#-------------------------------------------------------------- docker-compose #

the_host_name: "caleserver"
the_group: '{{ Raspbuntu }}'

DOMAIN: "{% for item in the_group %}{% if item.name == the_host_name %}{{ item.vars[0]['host'] }}{% endif %}{% endfor %}"
DUCKDNS_SUBDOMAINS: "{% for item in the_group %}{% if item.name == the_host_name %}{{ item.vars[0]['DUCKDNS_SUBDOMAINS'] }}{% endif %}{% endfor %}"
DUCKDNS_TOKEN: "{% for item in the_group %}{% if item.name == the_host_name %}{{ item.vars[0]['DUCKDNS_TOKEN'] }}{% endif %}{% endfor %}"
HASSDB_ROOT_PASSWD: "{% for item in the_group %}{% if item.name == the_host_name %}{{ item.vars[0]['HASSDB_ROOT_PASSWD'] }}{% endif %}{% endfor %}"
HASSDB_USER: "{% for item in the_group %}{% if item.name == the_host_name %}{{ item.vars[0]['HASSDB_USER'] }}{% endif %}{% endfor %}"
HASSDB_PASSWORD: "{% for item in the_group %}{% if item.name == the_host_name %}{{ item.vars[0]['HASSDB_PASSWORD'] }}{% endif %}{% endfor %}"


NEXTC_DB_ROOT_PASSWORD: "{% for item in the_group %}{% if item.name == the_host_name %}{{ item.vars[0]['NEXTC_DB_ROOT_PASSWORD'] }}{% endif %}{% endfor %}"
NEXTC_DB_USER: "{% for item in the_group %}{% if item.name == the_host_name %}{{ item.vars[0]['NEXTC_DB_USER'] }}{% endif %}{% endfor %}"
NEXTC_DB_PASSWORD: "{% for item in the_group %}{% if item.name == the_host_name %}{{ item.vars[0]['NEXTC_DB_PASSWORD'] }}{% endif %}{% endfor %}"

global_env_vars:
  - "PUID=1000"
  - "PGID=1000"
  - "TZ={{ vault_TZ }}"
appdata_path: "/media/storage/config"
appdata_path_cached: "/media/cached_storage/config"        # Because of mergerfs
video_path: "/media/storage/Videos"
downloads_path: "/media/storage/Downloads"
container_config_path: /config

containers:
  - service_name: bazarr
    active: true
    include_global_env_vars: true
    container_name: bazarr
    image: linuxserver/bazarr:v0.9.0.7-ls97
    ports:
      - 6767:6767
    volumes:
      - "{{ appdata_path_cached }}/bazarr:/config"
      - "{{ video_path }}/Movies/:/movies"
      - "{{ video_path }}/TV/:/tv"
    depends_on:
      - radarr
      - sonarr
    healthcheck:
      test_port: "6767"
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  - service_name: bitwarden
    active: true
    include_global_env_vars: true
    container_name: bitwarden
    image: bitwardenrs/server:raspberry
    ports:
      - 9085:80
    volumes:
      - "{{ appdata_path_cached }}/bitwarden:/data"
    depends_on:
      - duckdns
      - caddy
    healthcheck:
      test_port: "80"
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  - service_name: caddy
    active: true
    include_global_env_vars: true
    container_name: caddy
    image: caddy:2.2.1-alpine
    ports:
      - 80:80
      - 443:443
    volumes:
      - /var/run/docker.sock:/tmp/docker.sock:ro                          # For docker
      - "{{ appdata_path }}/caddy/Caddyfile:/etc/caddy/Caddyfile"         # Caddyfile
      - "{{ appdata_path }}/caddy/data:{{ container_config_path }}/caddy" # certificates
      - "{{ appdata_path }}/caddy/config:{{ container_config_path }}"     # json
    environment:
      - "DOMAIN={{ DOMAIN }}"
    depends_on:
      - duckdns
    restart: unless-stopped

  - service_name: duckdns
    active: true
    include_global_env_vars: true
    image: ghcr.io/linuxserver/duckdns:67a3afee-ls60
    environment:
      - "SUBDOMAINS={{ DUCKDNS_SUBDOMAINS }}"
      - "TOKEN={{ DUCKDNS_TOKEN }}"
    restart: unless-stopped

  - service_name: emby
    active: true
    include_global_env_vars: true
    image: linuxserver/emby:arm64v8-4.5.2.0-ls60
    devices:
      - /dev/vchiq:/dev/vchiq
      - /dev/video10:/dev/video10
      - /dev/video11:/dev/video11
      - /dev/video12:/dev/video12
    ports:
      - 8096:8096
    volumes:
      - "{{ appdata_path_cached }}/emby:/config"
      - "{{ video_path }}/Movies:/movies"
      - "{{ video_path }}/TV:/tvshows"
      - /opt/vc/lib:/opt/vc/lib
    healthcheck:
      test_port: 8096
      interval: 30s
      timeout: 10s
      retries: 6
    restart: unless-stopped

  - service_name: grafana
    active: true
    image: grafana/grafana
    user: "{{ docker_compose_generator_uid }}:{{ docker_compose_generator_gid }}"
    ports:
      - 3000:3000
    networks:
      automation:
        ipv4_address: 172.92.92.97
    volumes:
      - "{{ appdata_path_cached }}/grafana:/var/lib/grafana"
    restart: unless-stopped

  - service_name: heimdall
    active: true
    include_global_env_vars: true
    image: ghcr.io/linuxserver/heimdall:2.2.2-ls108
    ports:
      - 8080:80
    volumes:
      - "{{ appdata_path }}/heimdall:/config"
    healthcheck:
      test_port: 80
      interval: 30s
      timeout: 10s
      retries: 6
    restart: unless-stopped

  - service_name: homeassistant
    active: true
    include_global_env_vars: true
    container_name: homeassistant
    image: homeassistant/raspberrypi4-homeassistant:0.117.6
    network_mode: host
    volumes:
      - "{{ appdata_path }}/homeassistant:/config"
      - /etc/localtime:/etc/localtime:ro
      - "{{ appdata_path }}/homeassistant/docker/run:/etc/services.d/home-assistant/run"
    extra_hosts:
      - "hass-db:172.92.92.92"
      - "homeassistant_metrics:172.92.92.94"
    environment:
      - PACKAGES=iputils
    depends_on:
      - caddy
      - mosquitto
      - homeassistant_db
      - node-red
      - homeassistant_metrics
    healthcheck:
      test_port: 8123
      interval: 30s
      timeout: 10s
      retries: 6
    restart: unless-stopped

  - service_name: homeassistant_db
    active: true
    include_global_env_vars: true
    image: ghcr.io/linuxserver/mariadb:110.4.17mariabionic-ls1
    environment:
      - "MYSQL_ROOT_PASSWORD={{ HASSDB_ROOT_PASSWD }}"
      - "MYSQL_DATABASE=homeassistant"
      - "MYSQL_USER={{ HASSDB_USER }}"
      - "MYSQL_PASSWORD={{ HASSDB_PASSWORD }}"
    volumes:
      - "{{ appdata_path_cached }}/homeassistant_db:/config"
    ports:
      - 3306:3306
    restart: unless-stopped
    networks:
      automation:
        ipv4_address: 172.92.92.92

  - service_name: homeassistant_metrics
    active: true
    image: influxdb:1.8
    user: "{{ docker_compose_generator_uid }}:{{ docker_compose_generator_gid }}"
    networks:
      automation:
        ipv4_address: 172.92.92.94
    volumes:
      - "{{ appdata_path_cached }}/homeassistant_metrics:/var/lib/influxdb"
    restart: unless-stopped

  - service_name: jackett
    active: true
    include_global_env_vars: true
    container_name: jackett
    image: linuxserver/jackett:v0.16.2269-ls7
    ports:
      - 9117:9117
    volumes:
      - "{{ appdata_path }}/jackett:/config"
      - "{{ downloads_path }}/watch:/downloads"
    healthcheck:
      test_port: "9117"
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  - service_name: nextcloud
    active: true
    image: nextcloud:20
    ports:
      - 9999:80
    volumes:
      - "{{ appdata_path }}/nextcloud:/var/www/html"
    depends_on:
      - nextcloud_db
      - caddy
    healthcheck:
      test_port: "80"
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  - service_name: nextcloud_db
    active: true
    include_global_env_vars: true
    image: ghcr.io/linuxserver/mariadb:110.4.17mariabionic-ls1
    environment:
      - "MYSQL_ROOT_PASSWORD={{ NEXTC_DB_ROOT_PASSWORD }}"
      - "MYSQL_DATABASE=nextcloud"
      - "MYSQL_USER={{ NEXTC_DB_USER }}"
      - "MYSQL_PASSWORD={{ NEXTC_DB_PASSWORD }}"
    ports:
      - 3307:3306
    volumes:
      - "{{ appdata_path_cached }}/nextcloud_db:/config"
    restart: unless-stopped

  - service_name: node-red
    active: true
    image: nodered/node-red:1.2.5-minimal
    ports:
      - 1880:1880
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - "{{ appdata_path }}/node-red:/data"
      - "{{ volume_node_red_modules }}:/usr/src/node-red/node_modules"
      - /etc/timezone:/etc/timezone:ro 
    depends_on:
      - mosquitto
    healthcheck:
      test_port: "1880"
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  - service_name: mosquitto
    active: true
    image: eclipse-mosquitto:1.6
    restart: unless-stopped
    user: "{{ docker_compose_generator_uid }}:{{ docker_compose_generator_gid }}"
    ports:
      - 1883:1883
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - "{{ appdata_path }}/mosquitto:/mosquitto/config:ro"
      - "{{ appdata_path }}/mosquitto:/mosquitto/data"

  - service_name: ombi
    active: true
    include_global_env_vars: true
    image: linuxserver/ombi:v3.0.5223-ls76
    ports:
      - 3579:3579
    volumes:
      - "{{ appdata_path }}/ombi:/config"
    depends_on:
      - sonarr
      - radarr
    healthcheck:
      test_port: "3579"
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  - service_name: openwrt_metrics
    active: true
    image: influxdb
    user: "{{ docker_compose_generator_uid }}:{{ docker_compose_generator_gid }}"
    volumes:
      - "{{ appdata_path_cached }}/openwrt_metrics/db_data:/var/lib/influxdb"
      - "{{ appdata_path }}/openwrt_metrics/influxdb.conf:/etc/influxdb/influxdb.conf:ro"
      - "{{ appdata_path }}/openwrt_metrics/types.db:/usr/share/collectd/types.db:ro"
    ports:
      - 8083:8083
      - 8086:8086
      - 25826:25826/udp
    restart: unless-stopped

  - service_name: rancher
    active: false
    restart: unless-stopped
    image: rancher/rancher
    container_name: rancher
    privileged: true
    depends_on:
      - caddy
    volumes:
      - "{{ appdata_path }}/rancher:/var/lib/rancher"
    ports:
      - 8080:80
    command:
      - --no-cacerts

  - service_name: radarr
    active: true
    include_global_env_vars: true
    image: linuxserver/radarr:3.0.0.4204-ls85
    ports:
      - 7878:7878
    volumes:
      - "{{ appdata_path_cached }}/radarr:/config"
      - "{{ video_path }}/Movies:/movies"
      - "{{ downloads_path }}:/downloads"
    depends_on:
      - jackett
      - transmission
    healthcheck:
      test_port: "7878"
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  - service_name: sonarr
    active: true
    include_global_env_vars: true
    image: linuxserver/sonarr:2.0.0.5344-ls87
    ports:
      - 8989:8989
    volumes:
      - "{{ appdata_path_cached }}/sonarr:/config"
      - "{{ video_path }}/TV:/tv"
      - "{{ downloads_path }}:/downloads"
    depends_on:
      - jackett
      - transmission
    healthcheck:
      test_port: "8989"
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  - service_name: transmission
    active: true
    include_global_env_vars: true
    image: linuxserver/transmission:3.00-r0-ls69
    ports:
      - 9091:9091
      - 51413:51413
      - 51413:51413/udp
    volumes:
      - "{{ appdata_path }}/transmission:/config"
      - "{{ downloads_path }}/:/downloads"
      - "{{ video_path }}/watch:/watch"
    healthcheck:
      test_port: "9091"
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

# volumes
volume_node_red_modules: "node-red-modules"

volumes:
  - volume_name: "{{ volume_node_red_modules }}"
    active: true

networks:
  - network_name: automation
    active: true
    driver: bridge
    ipam:
      config:
        - subnet: 172.92.92.0/24
